<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.65.2" /><meta name="theme-color" content="#fff" />
        <script>
            const userPrefers = localStorage.getItem('theme');
            const darkModeMediaQuery = window.matchMedia('(prefers-color-scheme: dark)');
            const lightModeMediaQuery = window.matchMedia('(prefers-color-scheme: light)');
            if (userPrefers === 'dark') {
                changeModeMeta('dark');
            } else if (userPrefers === 'light') {
                changeModeMeta('light');
            } else if (darkModeMediaQuery.matches) {
                changeModeMeta('dark');
            } else if (lightModeMediaQuery.matches) {
                changeModeMeta('light');
            }
            function changeModeMeta(theme) {
                document.documentElement.setAttribute('data-theme', theme);
                if (theme === 'dark') {
                    changeThemeColor('#1c1c21');
                } else {
                    changeThemeColor('#fff');
                }
            }
            function changeThemeColor(themeColor) {
                document.querySelector('meta[name="theme-color"]').setAttribute('content', themeColor);
            }
        </script>

    
        
        
        <script>
            if (window.location.host == "iyuanshuo.com" && window.location.protocol != "https:") {
                window.location.protocol = "https";
            }
        </script>

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=2.0, user-scalable=yes" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>GBDT 梯度提升树的基本原理 | Shuo Yuan&#39;s Home Page</title>

    <link rel="stylesheet" href="/css/meme.min.4a906cbabc6eeb8d956adef99799b9cabf6f757036617ff42df017220e988912.css" integrity="sha256-SpBsurxu642Vat75l5m5yr9vdXA2YX/0LfAXIg6YiRI=" data-instant-track />

    <link href="https://fonts.googleapis.com/css?family=EB+Garamond:400,400i,700,700i|Noto+Serif+SC:400,700|Source+Code+Pro:400,400i,700,700i|Cinzel+Decorative:700&display=swap&subset=chinese-simplified" rel="stylesheet" />

    <meta name="author" content="Shuo Yuan" />
    
    
    <meta name="description" content="什么是GBDT? GBDT (Gradient Boosting Decision Tree) 是一种基于boosting集成学习（ensemble met……" />

    <link rel="shortcut icon" type="image/ico" href="/favicon.ico" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="Shuo Yuan&#39;s Home Page" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="Shuo Yuan&#39;s Home Page" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://iyuanshuo.com/tech/gbdt-principle-2018031321/" />



<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2018-03-13T21:26:42+00:00",
        "dateModified": "2020-02-27T15:56:08+08:00",
        "url": "https://iyuanshuo.com/tech/gbdt-principle-2018031321/",
        "headline": "GBDT 梯度提升树的基本原理",
        "description": "什么是GBDT? GBDT (Gradient Boosting Decision Tree) 是一种基于boosting集成学习（ensemble met……",
        "inLanguage" : "zh-CN",
        "articleSection": "tech",
        "wordCount":  2375 ,
        "image": ["http://images.iyuanshuo.com//blog/article/GBDT.png","http://images.iyuanshuo.com//blog/article/GBDT%20algorithm.png"],
        "author": {
            "@type": "Person",
            "description": "Stay Hungry Stay Foolish",
            "email": "isaulyuan@gmail.com",
            "image": "https://iyuanshuo.com/icons/apple-touch-icon.png",
            "url": "https://iyuanshuo.com/",
            "name": "Shuo Yuan"
        },
        "license": "在保留本文作者及本文链接的前提下，非商业用途随意转载分享。",
        "publisher": {
            "@type": "Organization",
            "name": "Shuo Yuan's Home Page",
            "logo": {
                "@type": "ImageObject",
                "url": "https://iyuanshuo.com/icons/apple-touch-icon.png"
            },
            "url": "https://iyuanshuo.com/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://iyuanshuo.com/"
        }
    }
</script>

    



<meta name="twitter:card" content="summary_large_image" />


<meta name="twitter:site" content="@saulyuan" />
<meta name="twitter:creator" content="@saulyuan" />

    





<meta property="og:title" content="GBDT 梯度提升树的基本原理" />
<meta property="og:description" content="什么是GBDT? GBDT (Gradient Boosting Decision Tree) 是一种基于boosting集成学习（ensemble met……" />
<meta property="og:url" content="https://iyuanshuo.com/tech/gbdt-principle-2018031321/" />
<meta property="og:site_name" content="Shuo Yuan&#39;s Home Page" />
<meta property="og:locale" content="zh-CN" />
            <meta property="og:locale:alternate" content="en-US" />
        <meta property="og:image" content="http://images.iyuanshuo.com//blog/article/GBDT.png" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2018-03-13T21:26:42+00:00" />
    <meta property="article:modified_time" content="2020-02-27T15:56:08+08:00" />
    
    <meta property="article:section" content="tech" />


        


    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q09QFXNCE9"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-Q09QFXNCE9');
    </script>




    
        <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        <div class="site-brand">
            
            <a href="/"><svg xmlns="http://www.w3.org/2000/svg" class="brand" width="34" height="10"><text data-name="Shuo Yuan" x="20" y="55" font-family="Palatino Linotype" font-size="45">Shuo Yuan</text><text data-name="Stay Hungry Stay Foolish" x="30" y="81" font-size="18" font-family="Trebuchet MS">Stay Hungry Stay Foolish</text></svg></a>
            
        </div>
    </header>

            
            <div class="lang-toggle" onmouseover="langSwitcherOver()" onmouseout="langSwitcherOut()">
        🇨🇳
        
            
                <ul id="langs">
                    
                        
                    
                        
                            <li><a rel="alternate" href="/en-us" hreflang="en-us" lang="en-us">🇺🇸</a></li>
                        
                    
                </ul>
            
        
    </div>

            
    
        
            
        
        <div id="theme-toggle" onclick="modeSwitcher()">🌞</div>
    

            
    <main class="main single" id="main">
    <div class="main-inner">
        
        <div class="links">
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="/archives/" class="links-item"><svg t="1582383197269" class="icon archives" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4424" width="200" height="200"><path d="M608 480q0-13-9.5-22.5t-22.5-9.5l-128 0q-13 0-22.5 9.5t-9.5 22.5 9.5 22.5 22.5 9.5l128 0q13 0 22.5-9.5t9.5-22.5zm288-96l0 480q0 13-9.5 22.5t-22.5 9.5l-704 0q-13 0-22.5-9.5t-9.5-22.5l0-480q0-13 9.5-22.5t22.5-9.5l704 0q13 0 22.5 9.5t9.5 22.5zm32-224l0 128q0 13-9.5 22.5t-22.5 9.5l-768 0q-13 0-22.5-9.5t-9.5-22.5l0-128q0-13 9.5-22.5t22.5-9.5l768 0q13 0 22.5 9.5t9.5 22.5z" p-id="4425"></path></svg>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
            <a href="/" class="links-item"><svg t="1582382816192" class="icon home" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2039" width="200" height="200"><path d="M999.936 509.44l-449.024-389.12c-9.216-11.264-23.552-18.432-38.912-18.432s-29.696 7.168-38.912 18.432l-449.024 389.12C9.728 518.656 0 534.528 0 552.96c0 26.624 19.968 48.128 46.08 50.688v0.512h81.92v317.44c0 28.16 23.04 51.2 51.2 51.2h204.8c28.16 0 51.2-23.04 51.2-51.2v-209.92c0-28.16 23.04-51.2 51.2-51.2h51.2c28.16 0 51.2 23.04 51.2 51.2v209.92c0 28.16 23.04 51.2 51.2 51.2h204.8c28.16 0 51.2-23.04 51.2-51.2v-317.44h76.8c28.16 0 51.2-23.04 51.2-51.2 0-18.432-9.728-34.304-24.064-43.52z" fill="#1296db" p-id="2040"></path></svg>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
            <a href="/about/" class="links-item"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon about"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
            
        </div>
        
        <article class="content post" data-align="justify" data-type="tech">

            <h1 class="post-title">GBDT 梯度提升树的基本原理</h1>

            

            
                
            

            

            
                <nav class="contents">
  <h2 id="contents" class="contents-title">目录</h2><ol class="toc">
    <li><a id="contents:什么是gbdt" href="#什么是gbdt">什么是GBDT?</a>
      <ol>
        <li><a id="contents:boost" href="#boost">Boost</a></li>
        <li><a id="contents:gradient-boosting" href="#gradient-boosting">Gradient Boosting</a></li>
      </ol>
    </li>
    <li><a id="contents:gbdt算法" href="#gbdt算法">GBDT算法</a>
      <ol>
        <li><a id="contents:gbdt回归算法" href="#gbdt回归算法">GBDT回归算法</a></li>
        <li><a id="contents:gbdt分类算法" href="#gbdt分类算法">GBDT分类算法</a>
          <ol>
            <li><a id="contents:二元gbdt分类算法" href="#二元gbdt分类算法">二元GBDT分类算法</a></li>
            <li><a id="contents:多元gbdt分类算法" href="#多元gbdt分类算法">多元GBDT分类算法</a></li>
          </ol>
        </li>
      </ol>
    </li>
  </ol>
</nav><div class="post-body"><h2 id="什么是gbdt"><a href="#什么是gbdt" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:什么是gbdt" class="headings">什么是GBDT?</a></h2>
<p>GBDT (Gradient Boosting Decision Tree) 是一种基于boosting集成学习（ensemble method）的算法，但和传统的Adaboost有很大不同。在Adaboost，我们是利用前一轮迭代弱学习器的误差率来更新训练集的权重，这样一轮轮的迭代下去。GBDT也是迭代，使用了前向分布算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。GBDT选用的弱分类器一般是低方差高偏差，因为Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成。GBDT的训练过程如下<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">[1]</a></sup>：</p>
<p><img src="http://images.iyuanshuo.com//blog/article/GBDT.png" alt="Fig 1. GBDT 的训练过程" data-zoomable></p>
<h3 id="boost"><a href="#boost" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:boost" class="headings">Boost</a></h3>
<p>Boost是一个加法模型，它是由若干个基函数及其权值乘积之和的累加。</p>
<h3 id="gradient-boosting"><a href="#gradient-boosting" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gradient-boosting" class="headings">Gradient Boosting</a></h3>
<p>GBDT是把所有树的结论累加起来做最终结论的，所以可以想到每棵树的结论并不是年龄本身，而是年龄的一个累加量。GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">[2]</a></sup>。</p>
<p>根据上面那个简单的例子，我们知道假设损失函数为平方损失（square loss）时，我们使用残差来进行下一轮的训练，即GBDT算法的每一步在生成决策树时只需要拟合前面的模型的残差，从而使得损失函数最小。那如何使损失函数最小呢？Freidman提出了用损失函数的负梯度来拟合本轮损失的近似值，进而拟合一个CART回归树，这就是GBDT的负梯度拟合。损失函数的负梯度在当前模型的值为：</p>
<div>$$
-[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}
$$</div>
<p>Boosting的最大好处在于，每一步的残差计算其实变相地增大了分错样本的权重，而已经分对的样本则都趋向于0。因为对于已经分对的样本，其残差为0，在下一轮中几乎不起作用。</p>
<h2 id="gbdt算法"><a href="#gbdt算法" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gbdt算法" class="headings">GBDT算法</a></h2>
<p>知道了怎么解决损失函数拟合的问题，即GBDT的负梯度拟合之后，需要使用这些负梯度进行训练。假设<span>$r_{mi}$</span>表示第<span>$m$</span>轮的第<span>$i$</span>个样本的损失函数的负梯度：</p>
<div>$$
r_{mi} = -\bigg[\frac{\partial L(y_i, f(x_i)))}{\partial f(x_i)}\bigg]_{f(x) = f_{m-1}\;\; (x)}
$$</div>
<p>利用<span>$(x_i,r_{mi})\quad(i=1,2,..n)$</span>，我们可以拟合第<span>$m$</span>棵CART回归树，其对应的叶节点区域<span>$R_{mj}, j =1,2,..., J$</span>，其中<span>$J$</span>为叶子节点的个数。</p>
<p>针对每个叶子节点里的样本，我们求出损失函数最小，也就是拟合叶子节点最好的的输出值<span>$c_{mj}$</span>如下：</p>
<div>$$
c_{mj} = \underbrace{arg\; min}_{c}\sum\limits_{x_i \in R_{mj}} L(y_i,f_{m-1}(x_i) +c)
$$</div>
<p>从而可以获得本轮的CART回归树的拟合函数：</p>
<div>$$
h_m(x) = \sum\limits_{j=1}^{J}c_{mj}I(x \in R_{mj})
$$</div>
<p>最后获得强学习器的表达式：</p>
<div>$$
f_{m}(x) = f_{m-1}(x) + \sum\limits_{j=1}^{J}c_{mj}I(x \in R_{mj})
$$</div>
<p>请结合上面的例子，理解每一轮更新强学习器都需要加上前面所有轮的输出！</p>
<h3 id="gbdt回归算法"><a href="#gbdt回归算法" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gbdt回归算法" class="headings">GBDT回归算法</a></h3>
<p>Freidman提出的梯度提升(Gradient Boosting)算法：利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。算法如下<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">[3]</a></sup>：</p>
<p><img src="http://images.iyuanshuo.com//blog/article/GBDT%20algorithm.png" alt="" data-zoomable></p>
<p>算法步骤解释：</p>
<p>1、初始化，估计使损失函数极小化的常数值，它是只有一个根节点的树，即<span>$\gamma$</span>是一个常数值；</p>
<p>2、对于每轮CART回归树：</p>
<pre><code>（a）计算损失函数的负梯度在当前模型的值，将它作为残差的估计
（b）估计回归树叶节点区域，以拟合残差的近似值
（c）利用线性搜索估计叶节点区域的值，使损失函数极小化
（d）更新回归树
</code></pre>
<p>3、得到输出的最终模型 <span>$f(x)$</span>。</p>
<h3 id="gbdt分类算法"><a href="#gbdt分类算法" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:gbdt分类算法" class="headings">GBDT分类算法</a></h3>
<p>这里我们再看看GBDT分类算法，GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">[4]</a></sup>。</p>
<p>为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时GBDT退化为AdaBoost算法。另一种方法是用类似于逻辑回归的对数似然损失函数。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。本文仅讨论用对数似然损失函数的GBDT分类。而对于对数似然损失函数，我们又有二元分类和多元分类的区别。</p>
<h4 id="二元gbdt分类算法"><a href="#二元gbdt分类算法" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:二元gbdt分类算法" class="headings">二元GBDT分类算法</a></h4>
<p>对于二元GBDT，如果用类似于逻辑回归的对数似然损失函数，则损失函数为：</p>
<div>$$
(y, f(x)) = log(1+ exp(-yf(x)))
$$</div>
<p>其中<span>$y \in{-1, +1}$</span>。此时的负梯度误差为：</p>
<div>$$
r_{mi} = -\bigg[\frac{\partial L(y, f(x_i)))}{\partial f(x_i)}\bigg]_{f(x) = f_{m-1}\;\; (x)} = y_i/(1+exp(y_if(x_i)))
$$</div>
<p>对于生成的CART回归树，我们各个叶子节点的最佳残差拟合值为：</p>
<div>$$
c_{mj} = \underbrace{arg\; min}_{c}\sum\limits_{x_i \in R_{mj}} log(1+exp(-y_i(f_{m-1}(x_i) +c)))
$$</div>
<p>由于上面的式子比较难优化，一般使用近似值代替：</p>
<div>$$
c_{mj} = \sum\limits_{x_i \in R_{mj}}r_{mi}\bigg /  \sum\limits_{x_i \in R_{mj}}|r_{mi}|(1-|r_{mi}|)
$$</div>
<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，二元GBDT分类和GBDT回归算法过程相同。</p>
<h4 id="多元gbdt分类算法"><a href="#多元gbdt分类算法" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:多元gbdt分类算法" class="headings">多元GBDT分类算法</a></h4>
<p>多元GBDT要比二元GBDT复杂一些，对应的是多元逻辑回归和二元逻辑回归的复杂度差别。假设类别数为K，则此时我们的对数似然损失函数为：</p>
<div>$$
L(y, f(x)) = -  \sum\limits_{k=1}^{K}y_klog\;p_k(x)
$$</div>
<p>其中如果样本输出类别为<span>$k$</span>，则<span>$y_{k}=1$</span>。第<span>$k$</span>类的概率<span>$p_{k}(x)$</span>的表达式为：</p>
<div>$$
p_k(x) = exp(f_k(x)) \bigg / \sum\limits_{l=1}^{K} exp(f_l(x))
$$</div>
<p>集合上两式，我们可以计算出第<span>$t$</span>轮的第<span>$i$</span>个样本对应类别<span>$l$</span>的负梯度误差为:</p>
<div>$$
r_{mil} = -\bigg[\frac{\partial L(y_i, f(x_i)))}{\partial f(x_i)}\bigg]_{f_k(x) = f_{l, m-1}\;\; (x)} = y_{il} - p_{l, m-1}(x_i)
$$</div>
<p>观察上式可以看出，其实这里的误差就是样本<span>$i$</span>对应类别<span>$l$</span>的真实概率和<span>$m−1$</span>轮预测概率的差值。</p>
<p>对于生成的决策树，我们各个叶子节点的最佳残差拟合值为:</p>
<div>$$
c_{mjl} = \underbrace{arg\; min}_{c_{jl}}\sum\limits_{i=0}^{m}\sum\limits_{k=1}^{K} L(y_k, f_{m-1, l}(x) + \sum\limits_{j=0}^{J}c_{jl} I(x_i \in R_{mj}))
$$</div>
<p>由于上式比较难优化，我们一般使用近似值代替:</p>
<div>$$
c_{mjl} =  \frac{K-1}{K} \; \frac{\sum\limits_{x_i \in R_{mjl}}r_{mil}}{\sum\limits_{x_i \in R_{mil}}|r_{mil}|(1-|r_{mil}|)}
$$</div>
<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，多元GBDT分类和二元GBDT分类以及GBDT回归算法过程相同。</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.cnblogs.com/ModifyRong/p/7744987.html" target="_blank" rel="noopener">机器学习算法GBDT</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512" class="icon footnote-icon"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 329.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg></a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://mp.weixin.qq.com/s/li2_zhx8D6wia6ZgeH9xiA?" target="_blank" rel="noopener">GBDT之原理、所解决的问题、应用场景</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512" class="icon footnote-icon"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 329.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg></a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.google.com/search?q=The%20Elements%20of%20Statistical%20Learning" target="_blank" rel="noopener">The Elements of Statistical Learning</a> <a href="#fnref:3" class="footnote-backref" role="doc-backlink"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512" class="icon footnote-icon"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 329.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg></a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.cnblogs.com/pinard/p/6140514.html" target="_blank" rel="noopener">梯度提升树 (GBDT) 原理小结</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512" class="icon footnote-icon"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 329.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg></a></p>
</li>
</ol>
</section>
</div>

        </article>

        

        

        

        

        
    
    

<div class="post-share">

        

        <div class="share-items">

            
                
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;text=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&amp;via=saulyuan" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            
                
                <div class="share-item facebook">
                    
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https://iyuanshuo.com/tech/gbdt-principle-2018031321/" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                </div>
            

            
                
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;title=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&amp;summary=%e4%bb%80%e4%b9%88%e6%98%afGBDT?%20GBDT%20%28Gradient%20Boosting%20Decision%20Tree%29%20%e6%98%af%e4%b8%80%e7%a7%8d%e5%9f%ba%e4%ba%8eboosting%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%ef%bc%88ensemble%20met%e2%80%a6%e2%80%a6&amp;source=Shuo%20Yuan%27s%20Home%20Page" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;text=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            
                
                <div class="share-item weibo">
                    
                    <a href="https://service.weibo.com/share/share.php?&amp;url=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;title=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&amp;pic=http://images.iyuanshuo.com//blog/article/GBDT.png&amp;searchPic=false" title="分享到「新浪微博」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon weibo-icon"><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></a>
                </div>
            

            
                
                <div class="share-item douban">
                    
                    <a href="https://www.douban.com/share/service?href=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;name=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&amp;text=%e4%bb%80%e4%b9%88%e6%98%afGBDT?%20GBDT%20%28Gradient%20Boosting%20Decision%20Tree%29%20%e6%98%af%e4%b8%80%e7%a7%8d%e5%9f%ba%e4%ba%8eboosting%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%ef%bc%88ensemble%20met%e2%80%a6%e2%80%a6" title="分享到「豆瓣」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon douban-icon"><path d="M.643.92v2.412h22.714V.92H.643zm1.974 4.926v9.42h18.764v-9.42H2.617zm2.72 2.408H18.69v4.605H5.338V8.254zm1.657 7.412l-2.512.938c1.037 1.461 1.87 2.825 2.512 4.091H0v2.385h24v-2.385h-6.678c.818-1.176 1.589-2.543 2.303-4.091l-2.73-.938a29.952 29.952 0 01-2.479 5.03h-4.75c-.786-1.962-1.677-3.641-2.672-5.03Z"/></svg></a>
                </div>
            

            
                
                <div class="share-item qq">
                    
                    <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://iyuanshuo.com/tech/gbdt-principle-2018031321/&amp;title=GBDT%20%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86&amp;summary=%e4%bb%80%e4%b9%88%e6%98%afGBDT?%20GBDT%20%28Gradient%20Boosting%20Decision%20Tree%29%20%e6%98%af%e4%b8%80%e7%a7%8d%e5%9f%ba%e4%ba%8eboosting%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%ef%bc%88ensemble%20met%e2%80%a6%e2%80%a6&amp;pics=http://images.iyuanshuo.com//blog/article/GBDT.png&amp;site=Shuo%20Yuan%27s%20Home%20Page" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </div>
            

            

            
                
                <div class="share-item qrcode">
                    <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script>
                        var typeNumber = 0;
                        var errorCorrectionLevel = 'L';
                        var qr = qrcode(typeNumber, errorCorrectionLevel);
                        qr.addData('https:\/\/iyuanshuo.com\/tech\/gbdt-principle-2018031321\/');
                        qr.make();
                        document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
                    </script>
                </div>
            

        </div>

    </div>



        

        

        
    <footer class="minimal-footer">
        
            
            <div class="post-tag"><a href="/tags/machinelearning/" rel="tag" class="post-tag-link">#machinelearning</a></div>
        
        
            <div class="post-category">
                <a href="/tech/" class="post-category-link active">tech</a> | 
            </div>
        
        
    </footer>


        

        

        

    </div>
</main>

            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>

            
        </div>
        <script src="/js/meme.min.b889c43157b752d7ae7ad4b9eb21e9bb2686995f67471c68e6982bf97fc44560.js" integrity="sha256-uInEMVe3UteuetS56yHpuyaGmV9nRxxo5pgr+X/ERWA=" data-no-instant></script>


    <script data-no-instant>InstantClick.init();</script>




    <script data-no-instant>
        InstantClick.on('change', function () {
            const userPrefers = localStorage.getItem('theme');
            const darkModeMediaQuery = window.matchMedia('(prefers-color-scheme: dark)');
            const lightModeMediaQuery = window.matchMedia('(prefers-color-scheme: light)');
            if (userPrefers === 'dark') {
                changeModeMeta('dark');
                changeMode('dark');
            } else if (userPrefers === 'light') {
                changeModeMeta('light');
                changeMode('light');
            } else if (darkModeMediaQuery.matches) {
                changeModeMeta('dark');
                changeMode('dark');
            } else if (lightModeMediaQuery.matches) {
                changeModeMeta('light');
                changeMode('light');
            }
        });
    </script>
<script data-no-instant>
            InstantClick.on('change', function () {
                gtag('config', 'G-Q09QFXNCE9', {
                    'page_path': location.pathname + location.search
                });
            });
        </script>
    
    
    <script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>

<script>
    var scroll = new SmoothScroll('a[href*="#"]', {
        speedAsDuration: true
    });
</script>





    <script>
    if (typeof MathJax === 'undefined') {
        window.MathJax = {
            loader: {
                load: ['[tex]/mhchem']
            },
            
            tex: {
                inlineMath: {'[+]': [['$', '$']]},
                tags: 'ams',
                packages: {'[+]': ['mhchem']}
            }
        };
        (function () {
            var script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js';
            script.defer = true;
            document.head.appendChild(script);
        })();
    } else {
        MathJax.texReset();
        MathJax.typeset();
    }
</script>





    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    mediumZoom('[data-zoomable]', {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <div class="app-refresh" id="app-refresh">
        <div class="app-refresh-wrap" onclick="location.reload()">
            <label>已更新最新版本</label>
            <span>点击刷新</span>
        </div>
    </div>

    <script>
        if ('serviceWorker' in navigator) {
            if (navigator.serviceWorker.controller) {
                navigator.serviceWorker.addEventListener('controllerchange', function() {
                    showNotification();
                });
            }

            window.addEventListener('load', function() {
                navigator.serviceWorker.register('../../sw.js');
            });
        }

        function showNotification() {
            document.querySelector('meta[name=theme-color]').content = '#000';
            document.getElementById('app-refresh').className += ' app-refresh-show';
        }
    </script>







    </body>
</html>
